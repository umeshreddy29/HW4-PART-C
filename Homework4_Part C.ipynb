{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MUOgIeG9aBLY",
        "outputId": "d5e14383-feb4-4951-efc2-e68fbf8a6929"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Filtered tokens (Word – Lemma – POS):\n",
            "enjoys     → enjoy      (VERB)\n",
            "playing    → play       (VERB)\n",
            "football   → football   (NOUN)\n",
            "reading    → read       (VERB)\n",
            "books      → book       (NOUN)\n",
            "library    → library    (NOUN)\n",
            "\n",
            "Lemmatized result: ['enjoy', 'play', 'football', 'read', 'book', 'library']\n"
          ]
        }
      ],
      "source": [
        "# Homework 4 Part C Q1\n",
        "# Text preprocessing pipeline: tokenization → stopword removal → lemmatization → POS filtering\n",
        "\n",
        "import spacy\n",
        "from nltk.corpus import stopwords\n",
        "import nltk\n",
        "\n",
        "# Download stopwords once if not already available\n",
        "nltk.download('stopwords')\n",
        "\n",
        "# Load spaCy English model\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "# Input sentence\n",
        "text = \"John enjoys playing football while Mary loves reading books in the library.\"\n",
        "\n",
        "# Process with spaCy\n",
        "doc = nlp(text)\n",
        "\n",
        "# Load English stopword list from NLTK\n",
        "stop_words = set(stopwords.words('english'))\n",
        "\n",
        "# Filtered tokens: keep non-stopword, alphabetic, lemma, POS = noun or verb\n",
        "filtered = [\n",
        "    (token.text, token.lemma_, token.pos_)\n",
        "    for token in doc\n",
        "    if token.is_alpha\n",
        "       and token.text.lower() not in stop_words\n",
        "       and token.pos_ in [\"NOUN\", \"VERB\"]\n",
        "]\n",
        "\n",
        "print(\"Filtered tokens (Word – Lemma – POS):\")\n",
        "for w, l, p in filtered:\n",
        "    print(f\"{w:10} → {l:10} ({p})\")\n",
        "\n",
        "# Optional: just the lemmatized output\n",
        "lemmas = [l for _, l, _ in filtered]\n",
        "print(\"\\nLemmatized result:\", lemmas)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Homework 4 Part C Q2\n",
        "# Named Entity Recognition + Pronoun ambiguity warning\n",
        "\n",
        "import spacy\n",
        "\n",
        "# Load spaCy English model\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "text = \"Chris met Alex at Apple headquarters in California. He told him about the new iPhone launch.\"\n",
        "\n",
        "# Run NER\n",
        "doc = nlp(text)\n",
        "\n",
        "print(\"Named Entities Detected:\")\n",
        "for ent in doc.ents:\n",
        "    print(f\" - {ent.text:25} → {ent.label_}\")\n",
        "\n",
        "# Detect pronouns\n",
        "pronouns = [t.text.lower() for t in doc if t.pos_ == \"PRON\"]\n",
        "\n",
        "# Check for third-person pronouns that could cause ambiguity\n",
        "ambiguous_prons = {\"he\", \"she\", \"they\", \"him\", \"her\", \"them\"}\n",
        "if any(p in ambiguous_prons for p in pronouns):\n",
        "    print(\"\\n⚠️ Warning: Possible pronoun ambiguity detected!\")\n",
        "else:\n",
        "    print(\"\\nNo pronoun ambiguity detected.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kz1zYr9GadwP",
        "outputId": "f8de7aa3-7a44-4e8f-e705-4f39a09a4cd2"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Named Entities Detected:\n",
            " - Chris                     → PERSON\n",
            " - Alex                      → PERSON\n",
            " - Apple                     → ORG\n",
            " - California                → GPE\n",
            " - iPhone                    → ORG\n",
            "\n",
            "⚠️ Warning: Possible pronoun ambiguity detected!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "UBDRsDFCaSFH"
      }
    }
  ]
}